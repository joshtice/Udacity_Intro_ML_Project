{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identity Fraud from Enron Email and Financial Data \n",
    "Joshua Tice\n",
    "## Introduction  \n",
    "The goal of this project was to use a supervised machine learning algorithm to identify Enron employees who committed fraud based on the public Enron Email and Financial Dataset. In addition to the financial information for certain Enron employees, the original dataset contained myriad emails that were exchanged between potential 'persons of interest' (poi's). Even though the main text of the emails were not analyzed in this project, the extent of the data available made machine learning a particularly useful tool. Learning algorithms could identify patterns and relationships in high-dimensional data that were difficult for a human mind to discern and help automate certain aspects of the analysis.  \n",
    "## Dataset background and EDA\n",
    "Before discussing the exploratory analysis of the dataset, a series of libraries and modules were loaded that were used throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# General imports\n",
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Udacity module imports\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "import tester\n",
    "from tester import dump_classifier_and_data\n",
    "from tester import test_classifier\n",
    "\n",
    "# Scikit-Learn imports\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score, recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Imbalanced-Learn imports\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curated dataset was provided by Udacity as a pickle file, which was subsequently loaded into a Python dictionary with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ported the dictionary into a Pandas dataframe so that I could perform a preliminary exploratory data analysis. I started by viewing the features that were available as well as a sample of the datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, METTS MARK to GLISAN JR BEN F\n",
      "Data columns (total 21 columns):\n",
      "bonus                        146 non-null object\n",
      "deferral_payments            146 non-null object\n",
      "deferred_income              146 non-null object\n",
      "director_fees                146 non-null object\n",
      "email_address                146 non-null object\n",
      "exercised_stock_options      146 non-null object\n",
      "expenses                     146 non-null object\n",
      "from_messages                146 non-null object\n",
      "from_poi_to_this_person      146 non-null object\n",
      "from_this_person_to_poi      146 non-null object\n",
      "loan_advances                146 non-null object\n",
      "long_term_incentive          146 non-null object\n",
      "other                        146 non-null object\n",
      "poi                          146 non-null bool\n",
      "restricted_stock             146 non-null object\n",
      "restricted_stock_deferred    146 non-null object\n",
      "salary                       146 non-null object\n",
      "shared_receipt_with_poi      146 non-null object\n",
      "to_messages                  146 non-null object\n",
      "total_payments               146 non-null object\n",
      "total_stock_value            146 non-null object\n",
      "dtypes: bool(1), object(20)\n",
      "memory usage: 24.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bonus</th>\n",
       "      <th>deferral_payments</th>\n",
       "      <th>deferred_income</th>\n",
       "      <th>director_fees</th>\n",
       "      <th>email_address</th>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <th>expenses</th>\n",
       "      <th>from_messages</th>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <th>...</th>\n",
       "      <th>long_term_incentive</th>\n",
       "      <th>other</th>\n",
       "      <th>poi</th>\n",
       "      <th>restricted_stock</th>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <th>salary</th>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <th>to_messages</th>\n",
       "      <th>total_payments</th>\n",
       "      <th>total_stock_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>METTS MARK</th>\n",
       "      <td>600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mark.metts@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94299</td>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1740</td>\n",
       "      <td>False</td>\n",
       "      <td>585062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365788</td>\n",
       "      <td>702</td>\n",
       "      <td>807</td>\n",
       "      <td>1061827</td>\n",
       "      <td>585062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAXTER JOHN C</th>\n",
       "      <td>1200000</td>\n",
       "      <td>1295738</td>\n",
       "      <td>-1386055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6680544</td>\n",
       "      <td>11200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1586055</td>\n",
       "      <td>2660303</td>\n",
       "      <td>False</td>\n",
       "      <td>3942714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5634343</td>\n",
       "      <td>10623258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELLIOTT STEVEN</th>\n",
       "      <td>350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-400729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>steven.elliott@enron.com</td>\n",
       "      <td>4890344</td>\n",
       "      <td>78552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12961</td>\n",
       "      <td>False</td>\n",
       "      <td>1788391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170941</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211725</td>\n",
       "      <td>6678735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CORDES WILLIAM R</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bill.cordes@enron.com</td>\n",
       "      <td>651850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>386335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1038185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HANNON KEVIN P</th>\n",
       "      <td>1500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3117011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kevin.hannon@enron.com</td>\n",
       "      <td>5538001</td>\n",
       "      <td>34039</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>1617011</td>\n",
       "      <td>11350</td>\n",
       "      <td>True</td>\n",
       "      <td>853064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>243293</td>\n",
       "      <td>1035</td>\n",
       "      <td>1045</td>\n",
       "      <td>288682</td>\n",
       "      <td>6391065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bonus deferral_payments deferred_income director_fees  \\\n",
       "METTS MARK         600000               NaN             NaN           NaN   \n",
       "BAXTER JOHN C     1200000           1295738        -1386055           NaN   \n",
       "ELLIOTT STEVEN     350000               NaN         -400729           NaN   \n",
       "CORDES WILLIAM R      NaN               NaN             NaN           NaN   \n",
       "HANNON KEVIN P    1500000               NaN        -3117011           NaN   \n",
       "\n",
       "                             email_address exercised_stock_options expenses  \\\n",
       "METTS MARK            mark.metts@enron.com                     NaN    94299   \n",
       "BAXTER JOHN C                          NaN                 6680544    11200   \n",
       "ELLIOTT STEVEN    steven.elliott@enron.com                 4890344    78552   \n",
       "CORDES WILLIAM R     bill.cordes@enron.com                  651850      NaN   \n",
       "HANNON KEVIN P      kevin.hannon@enron.com                 5538001    34039   \n",
       "\n",
       "                 from_messages from_poi_to_this_person  \\\n",
       "METTS MARK                  29                      38   \n",
       "BAXTER JOHN C              NaN                     NaN   \n",
       "ELLIOTT STEVEN             NaN                     NaN   \n",
       "CORDES WILLIAM R            12                      10   \n",
       "HANNON KEVIN P              32                      32   \n",
       "\n",
       "                 from_this_person_to_poi        ...         \\\n",
       "METTS MARK                             1        ...          \n",
       "BAXTER JOHN C                        NaN        ...          \n",
       "ELLIOTT STEVEN                       NaN        ...          \n",
       "CORDES WILLIAM R                       0        ...          \n",
       "HANNON KEVIN P                        21        ...          \n",
       "\n",
       "                 long_term_incentive    other    poi  restricted_stock  \\\n",
       "METTS MARK                       NaN     1740  False            585062   \n",
       "BAXTER JOHN C                1586055  2660303  False           3942714   \n",
       "ELLIOTT STEVEN                   NaN    12961  False           1788391   \n",
       "CORDES WILLIAM R                 NaN      NaN  False            386335   \n",
       "HANNON KEVIN P               1617011    11350   True            853064   \n",
       "\n",
       "                 restricted_stock_deferred  salary shared_receipt_with_poi  \\\n",
       "METTS MARK                             NaN  365788                     702   \n",
       "BAXTER JOHN C                          NaN  267102                     NaN   \n",
       "ELLIOTT STEVEN                         NaN  170941                     NaN   \n",
       "CORDES WILLIAM R                       NaN     NaN                      58   \n",
       "HANNON KEVIN P                         NaN  243293                    1035   \n",
       "\n",
       "                 to_messages total_payments total_stock_value  \n",
       "METTS MARK               807        1061827            585062  \n",
       "BAXTER JOHN C            NaN        5634343          10623258  \n",
       "ELLIOTT STEVEN           NaN         211725           6678735  \n",
       "CORDES WILLIAM R         764            NaN           1038185  \n",
       "HANNON KEVIN P          1045         288682           6391065  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data into dataframe for EDA\n",
    "df = pd.DataFrame.from_records(list(data_dict.values()))\n",
    "employees = pd.Series(list(data_dict.keys()))\n",
    "df.set_index(employees, inplace=True)\n",
    "\n",
    "# Basic EDA\n",
    "# Inspect features\n",
    "print(df.info())\n",
    "# Sample data at the head of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I saw that most of the features contained mixed datatypes due to the presence of 'NaN' strings included for missing values. I subsequently replaced these values with the numpy respresentation for null values and re-printed the info for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 146 entries, METTS MARK to GLISAN JR BEN F\n",
      "Data columns (total 21 columns):\n",
      "bonus                        82 non-null float64\n",
      "deferral_payments            39 non-null float64\n",
      "deferred_income              49 non-null float64\n",
      "director_fees                17 non-null float64\n",
      "email_address                111 non-null object\n",
      "exercised_stock_options      102 non-null float64\n",
      "expenses                     95 non-null float64\n",
      "from_messages                86 non-null float64\n",
      "from_poi_to_this_person      86 non-null float64\n",
      "from_this_person_to_poi      86 non-null float64\n",
      "loan_advances                4 non-null float64\n",
      "long_term_incentive          66 non-null float64\n",
      "other                        93 non-null float64\n",
      "poi                          146 non-null bool\n",
      "restricted_stock             110 non-null float64\n",
      "restricted_stock_deferred    18 non-null float64\n",
      "salary                       95 non-null float64\n",
      "shared_receipt_with_poi      86 non-null float64\n",
      "to_messages                  86 non-null float64\n",
      "total_payments               125 non-null float64\n",
      "total_stock_value            126 non-null float64\n",
      "dtypes: bool(1), float64(19), object(1)\n",
      "memory usage: 24.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Replace 'NaN' strings with Numpy nan representation\n",
    "df.replace('NaN', np.nan, inplace=True)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data had a mixture of financial features, features related to emails, and a classification. The 14 financial features were reported in units of US dollars:  \n",
    "* bonus\n",
    "* deferral payments\n",
    "* deferred income\n",
    "* director fees\n",
    "* exercised stock options\n",
    "* expenses\n",
    "* loan advances\n",
    "* long term incentive\n",
    "* other\n",
    "* restricted stock\n",
    "* restricted stock deferred\n",
    "* salary\n",
    "* total payments\n",
    "* total stock value  \n",
    "\n",
    "The 6 features related to emails were reported in units of counts (except email address, which was a string): \n",
    "\n",
    "* email address\n",
    "* from messages\n",
    "* from poi to this person\n",
    "* from this person to poi\n",
    "* shared receipt with poi\n",
    "* to messages  \n",
    "\n",
    "The classification feature (poi) was a boolean.\n",
    "\n",
    "I was interested in the allocation between the two different classes (poi and non-poi), because certain learning algorithms can be affected negatively by inbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points labelled 'POI': 18\n",
      "Data points labelled 'non-POI': 128\n",
      "Fraction of data points labelled 'POI': 0.12\n"
     ]
    }
   ],
   "source": [
    "# What is the allocation across classes (non-POI and POI)?\n",
    "count_poi = sum(df.poi)\n",
    "count_non_poi = sum(np.array(df.poi) == False)\n",
    "fraction_poi = count_poi / (count_poi + count_non_poi)\n",
    "print(\"Data points labelled 'POI': {}\".format(count_poi))\n",
    "print(\"Data points labelled 'non-POI': {}\".format(count_non_poi))\n",
    "print(\"Fraction of data points labelled 'POI': {:.2}\".format(fraction_poi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that the poi class composed only 12% of the data, I had to carefully adjust my learning algorithms and validation strategy later on to accommodate the imbalance.  \n",
    "\n",
    "Many of the features had a significant fraction of missing values. I re-sorted the features based on the number of 'nan's and also plotted a histogram to visualize the distribution of missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature | Number of missing values\n",
      "[('loan_advances', 142),\n",
      " ('director_fees', 129),\n",
      " ('restricted_stock_deferred', 128),\n",
      " ('deferral_payments', 107),\n",
      " ('deferred_income', 97),\n",
      " ('long_term_incentive', 80),\n",
      " ('bonus', 64),\n",
      " ('to_messages', 60),\n",
      " ('from_poi_to_this_person', 60),\n",
      " ('from_messages', 60),\n",
      " ('from_this_person_to_poi', 60),\n",
      " ('shared_receipt_with_poi', 60),\n",
      " ('other', 53),\n",
      " ('salary', 51),\n",
      " ('expenses', 51),\n",
      " ('exercised_stock_options', 44),\n",
      " ('restricted_stock', 36),\n",
      " ('email_address', 35),\n",
      " ('total_payments', 21),\n",
      " ('total_stock_value', 20),\n",
      " ('poi', 0)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFXCAYAAACYx4YhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMP8P8LpRQyS51hqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119d5ae90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Investigate missing values\n",
    "missing_value_dict = {}\n",
    "for col in df.columns:\n",
    "    missing_value_dict[col] = sum(df[col].isnull())\n",
    "print(\"Feature | Number of missing values\")\n",
    "pprint.pprint(sorted(missing_value_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "sns.distplot(missing_value_dict.values(), bins=range(0, 150, 10), kde=False)\n",
    "plt.xlabel('Number of missing values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some data analyses, a prevalance of missing values might have been a legitimate reason to remove a feature before implementing a learning algorithm. However, in this analysis, I knew that many persons of interest held positions at the top of the organization. Hence, features that might not have been relevant for an average employee (*e.g.*, director fees) might have been highly relevant to employees in upper management and consequently highly useful for the machine learning algorithm. Consequently, I did not remove any features based on missing values. In the above exploratory analysis, I represented missing values as 'nan's. However, when applying the learning algorithm, it made logical sense to represent the missing values as 0 USD or 0 counts. Code below provided by Udacity made this transformation during the data import process for machine learning.\n",
    "\n",
    "## Initial feature selection\n",
    "\n",
    "I did remove one feature at this stage - email address. I believed that the the email address of each individual was unlikely to contain any information relevant for machine learning. This feature was essentially a unique string identifier for each data point, and basically a redundant index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Task 1: Select what features you'll use.\n",
    "# features_list is a list of strings, each of which is a feature name.\n",
    "# The first feature must be \"poi\".\n",
    "\n",
    "feature_list = [\n",
    "    'poi',  \n",
    "    'bonus',\n",
    "    'deferral_payments',\n",
    "    'deferred_income',\n",
    "    'director_fees',\n",
    "    #'email_address',\n",
    "    'exercised_stock_options',\n",
    "    'expenses',\n",
    "    'from_messages',\n",
    "    'from_poi_to_this_person',\n",
    "    'from_this_person_to_poi',\n",
    "    'loan_advances',\n",
    "    'long_term_incentive',\n",
    "    'other',\n",
    "    'restricted_stock',\n",
    "    'restricted_stock_deferred',\n",
    "    'salary',\n",
    "    'shared_receipt_with_poi',\n",
    "    'to_messages',\n",
    "    'total_payments',\n",
    "    'total_stock_value'\n",
    "]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier removal\n",
    "\n",
    "Based on the \"Outliers\" lesson from Udacity's \"Intro to Machine Learning\" course, I knew that the data contained one outlier that needed to be removed - a data point corresponding to the cumulative total for each features. I did not remove any other outliers from the data because in this particular machine learning exercise, I was purposefully trying to identify individuals that could be seen as anomalies. In all likelihood, many of the outliers probably provided the most useful information for the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 2: Remove outliers\n",
    "del(data_dict['TOTAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of new features\n",
    "\n",
    "I created two new features from the supplied data. The first, 'ratio_poi_from_messages', was the number of emails sent from persons of interest to an individual normalized by the total number of emails the individual received. I reasoned that if a person received a high volume of emails in general (*e.g.*, an administrative assistant), then that person might also have a high count of emails from poi's by coincidence. The fraction of emails from poi might be a better indicator of affiliation with a poi. Likewise, I normalized the number of emails each individual sent to poi's by the total number of emails sent ('ratio_poi_to_messages')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 3: Create new feature(s)\n",
    "for key in data_dict.keys():\n",
    "    if (data_dict[key]['from_poi_to_this_person'] == 'NaN') or \\\n",
    "       (data_dict[key]['from_messages'] == 'NaN'):\n",
    "        data_dict[key]['ratio_poi_from_messages'] = 'NaN'\n",
    "    else:\n",
    "        data_dict[key]['ratio_poi_from_messages'] = \\\n",
    "        data_dict[key]['from_poi_to_this_person'] / \\\n",
    "        data_dict[key]['from_messages']\n",
    "    if (data_dict[key]['from_this_person_to_poi'] == 'NaN') or \\\n",
    "       (data_dict[key]['to_messages'] == 'NaN'):\n",
    "        data_dict[key]['ratio_poi_to_messages'] = 'NaN'\n",
    "    else:\n",
    "        data_dict[key]['ratio_poi_to_messages'] = \\\n",
    "        data_dict[key]['from_this_person_to_poi'] / \\\n",
    "        data_dict[key]['to_messages']\n",
    "feature_list.append('ratio_poi_from_messages')\n",
    "feature_list.append('ratio_poi_to_messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of Learning Algorithm\n",
    "\n",
    "In this section, I applied multiple learning algorithms to the data with the ultimate goal of achieving greater than 0.3 precision and recall for the 'poi' class. Early on, it became clear that one of the most critical aspects of the exercise was to choose an appropriate validation strategy. After rectifying the validation method, finding the appropriate learning algorithm became simpler.\n",
    "\n",
    "### Initial validation method\n",
    "\n",
    "Validation is the process of assessing how well a learning algorithm will perform. One classic mistake would be to train the learner on all the data available, and then to test the model on the same data. This approach would provide an overly optimistic estimate of the learner's abilities. A less-biased approach for validation is to split the data into separate training and test sets. The learner is trained on the training data, and then evaluated on data it has never seen. Initially, I adopted this simple train/test split strategy to validate the learning algorithms. Following Udacity's code, I split off 30% of the data for testing, and used the remaining 70% for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features and labels from dataset for local testing\n",
    "dataset = featureFormat(data_dict, feature_list, sort_keys=True)\n",
    "labels, features = targetFeatureSplit(dataset)\n",
    "\n",
    "# Initial test/train split validation method\n",
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1: Decision Trees \n",
    "\n",
    "The first algorithm I used was a simple decision tree. Decision trees have the advantage of yielding results that can be human interpretable, and they do not necessarily require feature scaling. I used sklearn's default parameters, except for the 'class_weight' parameter. Knowing that the classes were inherently unbalanced, I asked the algorithm to balance the weights in the training set such that 'poi' instances would have equal influence in the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up learning algorithm\n",
    "clf = DecisionTreeClassifier(\n",
    "    criterion='gini', \n",
    "    splitter='best',\n",
    "    max_depth=None, \n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features= 'sqrt',\n",
    "    random_state=42,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight='balanced',\n",
    "    presort=False\n",
    ")\n",
    "\n",
    "# Train algorithm\n",
    "clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two evaluation metrics of interest were the precision and recall of the test set. Precision is the fraction of true positives out of all cases classified positive, _i.e._:\n",
    "\n",
    "$$\\text{precision} = \\frac{\\text{true positives}}{\\text{true positives} + \\text{false positives}}$$\n",
    "\n",
    "Recall is the fraction of true positives out of all factually positive cases, _i.e._:\n",
    "\n",
    "$$\\text{precision} = \\frac{\\text{true positives}}{\\text{true positives} + \\text{false negatives}}$$\n",
    "\n",
    "The classification report I used also output the F1 scoring metric, which output a harmonic average of both precision and recall:\n",
    "\n",
    "$${\\displaystyle F_{1}=2\\cdot {\\frac {1}{{\\tfrac {1}{\\mathrm {precision} }}+{\\tfrac {1}{\\mathrm {recall} }}}}=2\\cdot {\\frac {\\mathrm {precision} \\cdot \\mathrm {recall} }{\\mathrm {precision} +\\mathrm {recall} }}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    non-poi       0.90      0.97      0.94        39\n",
      "        poi       0.50      0.20      0.29         5\n",
      "\n",
      "avg / total       0.86      0.89      0.86        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run report\n",
    "print(classification_report(labels_test, pred, target_names=['non-poi', 'poi']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial algorithm training managed to accomplish a precision of 0.50 and a recall of 0.20, which seemed optimistic. However, after experimentng with the code some more, I observed that the random state I assigned to the splitting code could drastically alter the outcome of the validation step.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test/train random state: 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    non-poi       0.89      0.92      0.91        37\n",
      "        poi       0.50      0.43      0.46         7\n",
      "\n",
      "avg / total       0.83      0.84      0.84        44\n",
      "\n",
      "Test/train random state: 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    non-poi       0.78      0.82      0.80        34\n",
      "        poi       0.25      0.20      0.22        10\n",
      "\n",
      "avg / total       0.66      0.68      0.67        44\n",
      "\n",
      "Test/train random state: 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    non-poi       0.83      0.92      0.87        37\n",
      "        poi       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.70      0.77      0.73        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try three different splits on the data, train the algorithm, and output results\n",
    "for i in range(3, 6):\n",
    "    features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=i)\n",
    "    clf.fit(features_train, labels_train)\n",
    "    pred = clf.predict(features_test)\n",
    "    print('Test/train random state: {}'.format(i))\n",
    "    print(classification_report(labels_test, pred, target_names=['non-poi', 'poi']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One random state could lead to a value of over 0.4 for both precision and recall for the poi class, while another could lead to a value of 0.0 for both. The variability in the results was probably due to several \n",
    "\n",
    "### Updated validation method\n",
    "\n",
    "I investigated other approaches in sklearn's user documentation, and I also inspected the validation code in Udacity's tester.py file. Initially, I attempted to bundle the core of Udacity's code into a custom validation method. However, the code was overly slow, perhaps given the number of loops it utilized. I decided to use sklearn's Repeated Stratified K-fold cross-validation class. Ultimately, this validation scheme emulated many of the key attributes of Udacity's code. It (i) stratified the data, assuring that a balanced number of non-poi and poi data points were in both the training and testing subsets, (ii) performed a k-fold cross-validation, which averaged error estimation over k number of validation trials, and (iii) allowed me to further average the results over a given number of cross-validation repeats, thus improving the robustness of the precision and recall estimates. I chose to do 10-fold cross-validation, in line with Udacity's testing code, and I used 100 repeats to balance robustness with processing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define validation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tandem, I also adjusted my code so that I could test several combinations of parameters in my learning algorithm using a grid search. SkLearn's GridSearchCV algorithm requires a scoring dictionary to define the metrics for output. I instantiated precision and recall scoring methods, purposefully setting the 'average' parameter to 'binary' such that the scorers only considered the positively labelled class, _i.e._, the poi class. The grid search cross-validation approach only uses only a single metric to find optimal hyperparameters, however, so I also instantiated an F1 scoring method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scoring metrics\n",
    "precision_scorer = make_scorer(precision_score, average='binary', pos_label=1)\n",
    "recall_scorer = make_scorer(recall_score, average='binary', pos_label=1)\n",
    "f1_scorer = make_scorer(f1_score, average='binary', pos_label=1)\n",
    "\n",
    "scoring_dict = {\n",
    "    'precision': precision_scorer,\n",
    "    'recall': recall_scorer,\n",
    "    'f1': f1_scorer\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I re-instantiated the decision tree algorithm, and I decided to tune the 'max_depth' and 'max_features' parameters. I purposefully interrogated small values for both of these parameters, knowing that decision trees have a tendency to overfit if they are allowed to grow excessively or if they are allowed to use too many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters {'max_features': 4, 'max_depth': 3}\n",
      "Precision: 0.383802827381\n",
      "Recall: 0.599930555556\n",
      "F1 score 0.44\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(\n",
    "    criterion='gini', \n",
    "    splitter='best',\n",
    "    max_depth=None, \n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features= 'sqrt',\n",
    "    random_state=42,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    class_weight='balanced',\n",
    "    presort=False\n",
    ")\n",
    "\n",
    "# Set hyperparameter tuning space\n",
    "param_grid = [\n",
    "    {\n",
    "        'max_depth': range(2, 5),\n",
    "        'max_features': range(3, 6),\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search optimization\n",
    "clf = GridSearchCV(tree, param_grid=param_grid, scoring=scoring_dict, cv=cv, refit='f1')\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# Output results for best algorithm hyperparameters\n",
    "print(\"Best parameters {}\".format(clf.best_params_))\n",
    "print(\"Precision: {}\".format(clf.cv_results_['mean_test_precision'][clf.best_index_]))\n",
    "print(\"Recall: {}\".format(clf.cv_results_['mean_test_recall'][clf.best_index_]))\n",
    "print(\"F1 score {:.2}\".format(clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome appeared to be successful when the number of features was set to 4 and the maximum depth of the tree was 3. To check against Udacity's standard, I ran the test_classifier method provided by Udacity with my optimized learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=3,\n",
      "            max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=42, splitter='best')\n",
      "\tAccuracy: 0.81687\tPrecision: 0.38525\tRecall: 0.62700\tF1: 0.47726\tF2: 0.55709\n",
      "\tTotal predictions: 15000\tTrue positives: 1254\tFalse positives: 2001\tFalse negatives:  746\tTrue negatives: 10999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_classifier(clf.best_estimator_, data_dict, feature_list=feature_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Udacity's cross-validation yielded a result similar to my cross-validation output, with both precision and recall of the poi class above 0.3.  \n",
    "Decision trees are sometimes relatively weak learners, and are sensitive to factors such as the initial state of the data or the initial features used in the tree splitting. I wanted to see if it was possible to increase the precision and recall even higher with an ensemble method.  \n",
    "\n",
    "### Algorithm 1 continued: Decision Trees with Adaptive Boosting  \n",
    "\n",
    "In an attmept to improve the performance of my decision tree algorithm, I used an adaptive boosting (adaboost) method to pool multiple learners into a stronger ensemble classifier. I used the same values of 'max_features' and 'max_depth' identified in the initial optimization performed above. Others have shown that the learning rate of the adaptive boosting algorithm ('learning_rate') and the number of estimators in the adaboost ensemble ('n_estimators') influence each other (Reference: [Trade-off between learning rate and number of learners](https://machinelearningmastery.com/tune-learning-rate-for-gradient-boosting-with-xgboost-in-python/)), so I tuned both of these parameters in the adaboost algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-782e8825c2ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Perform grid search optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Output results for best algorithm hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.pyc\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 expanded_class_weight = compute_sample_weight(\n\u001b[0;32m--> 159\u001b[0;31m                     self.class_weight, y_original)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.pyc\u001b[0m in \u001b[0;36mcompute_sample_weight\u001b[0;34m(class_weight, y, indices)\u001b[0m\n\u001b[1;32m    162\u001b[0m             weight_k = compute_class_weight(class_weight_k,\n\u001b[1;32m    163\u001b[0m                                             \u001b[0mclasses_full\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                                             y_full)\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mweight_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_full\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/joshuatice/anaconda/lib/python2.7/site-packages/sklearn/utils/class_weight.pyc\u001b[0m in \u001b[0;36mcompute_class_weight\u001b[0;34m(class_weight, classes, y)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         recip_freq = len(y) / (len(le.classes_) *\n\u001b[0;32m---> 55\u001b[0;31m                                np.bincount(y_ind).astype(np.float64))\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecip_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Decision Trees with Adaptive Boosting (AdaBoost)\n",
    "\n",
    "# Define classifier\n",
    "boost = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(\n",
    "        criterion='gini', \n",
    "        splitter='best',\n",
    "        max_depth=3, \n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        min_weight_fraction_leaf=0.0,\n",
    "        max_features= 4,\n",
    "        random_state=42,\n",
    "        max_leaf_nodes=None,\n",
    "        min_impurity_decrease=0.0,\n",
    "        min_impurity_split=None,\n",
    "        class_weight='balanced',\n",
    "        presort=False\n",
    "    ), \n",
    "    n_estimators=50, \n",
    "    learning_rate=1.0, \n",
    "    algorithm='SAMME.R', \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Set hyperparameter tuning space\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_estimators': [100, 300, 500],\n",
    "        'learning_rate': [0.001, 0.01, 0.1, 0.3],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Perform grid search optimization\n",
    "clf = GridSearchCV(boost, param_grid=param_grid, scoring=scoring_dict, cv=cv, refit='f1')\n",
    "clf.fit(features, labels)\n",
    "\n",
    "# Output results for best algorithm hyperparameters\n",
    "print(\"Best parameters {}\".format(clf.best_params_))\n",
    "print(\"Precision: {}\".format(clf.cv_results_['mean_test_precision'][clf.best_index_]))\n",
    "print(\"Recall: {}\".format(clf.cv_results_['mean_test_recall'][clf.best_index_]))\n",
    "print(\"F1 score {:.2}\".format(clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_classifier(clf.best_estimator_, data_dict, feature_list=feature_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TESTING TESTING (SCALER -> FEATURE SELECTION -> SVC)\n",
    "\n",
    "# Define validation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=100, random_state=42)\n",
    "\n",
    "# Scoring methods\n",
    "precision_scorer = make_scorer(precision_score, average='binary', pos_label=1)\n",
    "recall_scorer = make_scorer(recall_score, average='binary', pos_label=1)\n",
    "f1_scorer = make_scorer(f1_score, average='binary', pos_label=1)\n",
    "scoring_dict = {\n",
    "    'precision': precision_scorer,\n",
    "    'recall': recall_scorer,\n",
    "    'f1': f1_scorer\n",
    "}\n",
    "\n",
    "#Optional: class weights\n",
    "class_weight = {\n",
    "    0: 1,\n",
    "    1: 100\n",
    "}\n",
    "\n",
    "# Define pipeline components\n",
    "scaler = MinMaxScaler()\n",
    "feature_selection = SelectKBest(score_func=chi2)\n",
    "classifier = SVC(\n",
    "    C=1.0, \n",
    "    kernel='rbf', \n",
    "    degree=3, \n",
    "    gamma='auto', \n",
    "    coef0=0.0, \n",
    "    shrinking=True, \n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200, \n",
    "    class_weight='balanced', \n",
    "    verbose=False, \n",
    "    max_iter=-1, \n",
    "    decision_function_shape='ovr', \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "# Tune classifier with grid search \n",
    "param_grid = [\n",
    "    {\n",
    "        'feature_selection__k': range(3, 10),\n",
    "        'classifier__C': [10, 100, 1000]\n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid=param_grid, scoring=scoring_dict, cv=cv, refit='f1')\n",
    "clf.fit(features, labels)\n",
    "print(\"Best parameters {}\".format(clf.best_params_))\n",
    "print(\"Precision: {}\".format(clf.cv_results_['mean_test_precision'][clf.best_index_]))\n",
    "print(\"Recall: {}\".format(clf.cv_results_['mean_test_recall'][clf.best_index_]))\n",
    "print(\"F1 score {:.2}\".format(clf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision_scores = clf.cv_results_['mean_test_precision'].reshape(3, 7)\n",
    "recall_scores = clf.cv_results_['mean_test_recall'].reshape(3, 7)\n",
    "\n",
    "for i in range(3):\n",
    "    plt.plot(range(3, 10), precision_scores[i], label='Precision')\n",
    "    plt.plot(range(3, 10), recall_scores[i], label='Recall')\n",
    "    plt.title(\"SVC C Parameter: {}\".format(10**(i+1)), fontsize=16)\n",
    "    plt.xlabel(\"Number of features\")\n",
    "    plt.ylabel(\"Scores\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Which features are helping the most\n",
    "\n",
    "# Define pipeline elements\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(features)\n",
    "\n",
    "for i in range(4, 7):\n",
    "    feature_selection = SelectKBest(score_func=chi2, k=i)\n",
    "    feature_selection.fit(X, labels)\n",
    "    mask = feature_selection.get_support()\n",
    "    ranks = dict(zip(np.array(feature_list)[1:][mask], feature_selection.scores_))\n",
    "    print(\"Top features for k={}:\".format(i))\n",
    "    pprint.pprint(sorted(ranks.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pprint.pprint(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list_test = [\n",
    "    'poi', \n",
    "    #'bonus', \n",
    "    'exercised_stock_options', \n",
    "    #'loan_advances', \n",
    "    'total_stock_value',\n",
    "    'from_poi_to_this_person',\n",
    "    'from_this_person_to_poi'\n",
    "    #'ratio_poi_from_messages',\n",
    "    #'ratio_poi_to_messages'\n",
    "]\n",
    "    \n",
    "# Extract features and labels from dataset for local testing\n",
    "dataset_test = featureFormat(data_dict, feature_list, sort_keys=True)\n",
    "labels_test, features_test = targetFeatureSplit(dataset_test)\n",
    "\n",
    "# Define pipeline\n",
    "scaler = MinMaxScaler()\n",
    "classifier = SVC(\n",
    "    C=100, \n",
    "    kernel='rbf', \n",
    "    degree=3, \n",
    "    gamma='auto', \n",
    "    coef0=0.0, \n",
    "    shrinking=True, \n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200, \n",
    "    class_weight='balanced', \n",
    "    verbose=False, \n",
    "    max_iter=-1, \n",
    "    decision_function_shape='ovr', \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "clf_test = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "test_classifier(clf_test, data_dict, feature_list=feature_list_test, folds = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n",
    "\n",
    "Some of the features in the dataset had drastically different ranges. For instance, the features that I created above were purposefully created on a scale of 0 to 1, while some of the provided financial features had values in the millions of dollars. While not all learning algorithms require feature scaling, some could have substantially biased by non-normalized data, such as SVM's or linear models. To make sure all the features had similar ranges, I applied a simple min/max scaler to the data. At this point, the data were transferred to a Numpy array to be compatible with SciKit-Learn's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract features and labels from dataset for local testing\n",
    "dataset = featureFormat(data_dict, feature_list, sort_keys=True)\n",
    "labels, features = targetFeatureSplit(dataset)\n",
    "\n",
    "# Scale features \n",
    "#scaler = MinMaxScaler()\n",
    "#features = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SELECT FEATURES !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TESTING TESTING (GRADIENT BOOST TUNE)\n",
    "\n",
    "# Define validation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=100, random_state=42)\n",
    "# Scoring methods\n",
    "precision_scorer = make_scorer(precision_score, average='binary', pos_label=1)\n",
    "recall_scorer = make_scorer(recall_score, average='binary', pos_label=1)\n",
    "f1_scorer = make_scorer(f1_score, average='binary', pos_label=1)\n",
    "scoring_dict = {\n",
    "    'precision': precision_scorer,\n",
    "    'recall': recall_scorer,\n",
    "    'f1': f1_scorer\n",
    "}\n",
    "\n",
    "# Define classifier\n",
    "boost = GradientBoostingClassifier( \n",
    "    loss='deviance', \n",
    "    learning_rate=0.1, \n",
    "    n_estimators=100, \n",
    "    subsample=1.0, \n",
    "    criterion='friedman_mse', \n",
    "    min_samples_split=2, \n",
    "    min_samples_leaf=1, \n",
    "    min_weight_fraction_leaf=0.0, \n",
    "    max_depth=3, \n",
    "    min_impurity_decrease=0.0, \n",
    "    min_impurity_split=None, \n",
    "    init=None, \n",
    "    random_state=42, \n",
    "    max_features=None, \n",
    "    verbose=0, \n",
    "    max_leaf_nodes=None, \n",
    "    warm_start=False, \n",
    "    presort='auto'\n",
    ")\n",
    "\n",
    "# Tune classifier with grid search \n",
    "# Ref: https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "param_grid = [\n",
    "    {\n",
    "        #'n_estimators': [],\n",
    "        'learning_rate': [0.001, 0.01, 0.1],\n",
    "    }\n",
    "]\n",
    "clf = GridSearchCV(boost, param_grid=param_grid, scoring=scoring_dict, cv=cv, refit='recall')\n",
    "clf.fit(features, labels)\n",
    "print(\"Best parameters {}\".format(clf.best_params_))\n",
    "print(\"Best f1 score {:.2}\".format(clf.best_score_))\n",
    "print(\"Precision: {}\".format(clf.cv_results_['mean_test_precision'][clf.best_index_]))\n",
    "print(\"Recall: {}\".format(clf.cv_results_['mean_test_recall'][clf.best_index_]))\n",
    "print(\"Precision / Recall\")\n",
    "pprint.pprint(zip(clf.cv_results_['mean_test_precision'], clf.cv_results_['mean_test_recall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TESTING TESTING (LOGISITIC REGRESSION)\n",
    "\n",
    "# Define validation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=100, random_state=42)\n",
    "# Scoring methods\n",
    "precision_scorer = make_scorer(precision_score, average='binary', pos_label=1)\n",
    "recall_scorer = make_scorer(recall_score, average='binary', pos_label=1)\n",
    "f1_scorer = make_scorer(f1_score, average='binary', pos_label=1)\n",
    "scoring_dict = {\n",
    "    'precision': precision_scorer,\n",
    "    'recall': recall_scorer,\n",
    "    'f1': f1_scorer\n",
    "}\n",
    "\n",
    "class_weight = {\n",
    "    0: 1,\n",
    "    1: 1000\n",
    "}\n",
    "# Define classifier\n",
    "lm = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    dual=False, \n",
    "    tol=0.0001, \n",
    "    C=1.0, \n",
    "    fit_intercept=True, \n",
    "    intercept_scaling=1, \n",
    "    class_weight=class_weight, \n",
    "    random_state=42, \n",
    "    solver='liblinear', \n",
    "    max_iter=100, \n",
    "    multi_class='ovr', \n",
    "    verbose=0, \n",
    "    warm_start=False, \n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Tune classifier with grid search \n",
    "# Ref: https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "param_grid = [\n",
    "    {\n",
    "        'C': [1, 10, 100, 500, 1000], \n",
    "    }\n",
    "]\n",
    "clf = GridSearchCV(lm, param_grid=param_grid, scoring=scoring_dict, cv=cv, refit='precision')\n",
    "clf.fit(features, labels)\n",
    "print(\"Best parameters {}\".format(clf.best_params_))\n",
    "print(\"Best f1 score {:.2}\".format(clf.best_score_))\n",
    "print(\"Precision: {}\".format(clf.cv_results_['mean_test_precision'][clf.best_index_]))\n",
    "print(\"Recall: {}\".format(clf.cv_results_['mean_test_recall'][clf.best_index_]))\n",
    "print(\"Precision / Recall\")\n",
    "pprint.pprint(zip(clf.cv_results_['mean_test_precision'], clf.cv_results_['mean_test_recall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_test = clf.best_estimator_\n",
    "test_classifier(clf_test, data_dict, feature_list=feature_list, folds = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_test = clf.best_estimator_\n",
    "test_classifier(clf_test, data_dict, feature_list=feature_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TESTING TESTING (SUPPORT VECTOR MACHINE)\n",
    "\n",
    "# Define validation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=100, random_state=42)\n",
    "\n",
    "# Scoring methods\n",
    "precision_scorer = make_scorer(precision_score, average='binary', pos_label=1)\n",
    "recall_scorer = make_scorer(recall_score, average='binary', pos_label=1)\n",
    "f1_scorer = make_scorer(f1_score, average='binary', pos_label=1)\n",
    "scoring_dict = {\n",
    "    'precision': precision_scorer,\n",
    "    'recall': recall_scorer,\n",
    "    'f1': f1_scorer\n",
    "}\n",
    "\n",
    "# Class weights\n",
    "class_weight = {\n",
    "    0: 1,\n",
    "    1: 1000\n",
    "}\n",
    "\n",
    "# Define classifier\n",
    "svc = SVC(\n",
    "    C=1.0, \n",
    "    kernel='rbf', \n",
    "    degree=3, \n",
    "    gamma='auto', \n",
    "    coef0=0.0, \n",
    "    shrinking=True, \n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200, \n",
    "    class_weight=class_weight, \n",
    "    verbose=False, \n",
    "    max_iter=-1, \n",
    "    decision_function_shape='ovr', \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Tune classifier with grid search \n",
    "# Ref: https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "param_grid = [\n",
    "    {\n",
    "        'C': [1, 10, 100, 500, 1000], \n",
    "    }\n",
    "]\n",
    "clf = GridSearchCV(svc, param_grid=param_grid, scoring=scoring_dict, cv=cv, refit='f1')\n",
    "clf.fit(features, labels)\n",
    "print(\"Best parameters {}\".format(clf.best_params_))\n",
    "print(\"Best f1 score {:.2}\".format(clf.best_score_))\n",
    "print(\"Precision: {}\".format(clf.cv_results_['mean_test_precision'][clf.best_index_]))\n",
    "print(\"Recall: {}\".format(clf.cv_results_['mean_test_recall'][clf.best_index_]))\n",
    "print(\"Precision / Recall\")\n",
    "pprint.pprint(zip(clf.cv_results_['mean_test_precision'], clf.cv_results_['mean_test_recall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_test = clf.best_estimator_\n",
    "test_classifier(clf_test, data_dict, feature_list=feature_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_test = clf.best_estimator_\n",
    "test_classifier(clf_test, data_dict, feature_list=feature_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_test = pipe\n",
    "test_classifier(clf_test, data_dict, feature_list=feature_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TESTING TESTING (SCALER -> FEATURE SELECTION -> LOGISTIC REGRESSION)\n",
    "\n",
    "# Define validation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=100, random_state=42)\n",
    "# Scoring methods\n",
    "precision_scorer = make_scorer(precision_score, average='binary', pos_label=1)\n",
    "recall_scorer = make_scorer(recall_score, average='binary', pos_label=1)\n",
    "f1_scorer = make_scorer(f1_score, average='binary', pos_label=1)\n",
    "scoring_dict = {\n",
    "    'precision': precision_scorer,\n",
    "    'recall': recall_scorer,\n",
    "    'f1': f1_scorer\n",
    "}\n",
    "\n",
    "# Define pipeline\n",
    "scaler = MinMaxScaler()\n",
    "feature_selection = SelectKBest(score_func=chi2)\n",
    "classifier = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    dual=False, \n",
    "    tol=0.0001, \n",
    "    C=1.0, \n",
    "    fit_intercept=True, \n",
    "    intercept_scaling=1, \n",
    "    class_weight='balanced', \n",
    "    random_state=42, \n",
    "    solver='liblinear', \n",
    "    max_iter=100, \n",
    "    multi_class='ovr', \n",
    "    verbose=0, \n",
    "    warm_start=False, \n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "# Tune classifier with grid search \n",
    "param_grid = [\n",
    "    {\n",
    "        'feature_selection__k': range(3, 10),\n",
    "        'classifier__C': [1],\n",
    "        'classifier__class_weight': [{0:1, 1:10}, {0:1, 1:20}, {0:1, 1:50}]        \n",
    "    }\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(pipe, param_grid=param_grid, scoring=scoring_dict, cv=cv, refit='precision')\n",
    "clf.fit(features, labels)\n",
    "print(\"Best parameters {}\".format(clf.best_params_))\n",
    "pprint.pprint(zip(clf.cv_results_['mean_test_precision'], clf.cv_results_['mean_test_recall']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_test = pipe\n",
    "test_classifier(clf_test, data_dict, feature_list=feature_list, folds = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform additional features selection\n",
    "feature_selection = SelectKBest(score_func=chi2, k=10)\n",
    "feature_selection.fit(features, labels)\n",
    "mask = feature_selection.get_support()\n",
    "ranks = dict(zip(np.array(feature_list)[1:][mask], feature_selection.scores_))\n",
    "pprint.pprint(sorted(ranks.items(), key=lambda x: x[1], reverse=True))\n",
    "X = feature_selection.transform(features)\n",
    "# Up sample features to account for class imbalance\n",
    "upsampler = ADASYN(ratio='minority', random_state=42)\n",
    "X, y = upsampler.fit_sample(X, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation strategy\n",
    "\n",
    "If the learning algorithm was trained on the entire dataset, then the likelihood of overfitting would have been exacerbated. I would have no way of assessing the effecivenes of the learning algorithm when presented with previously unseen data. Hence, after scaling all of the data, I split the data into a training set and a test set for validation purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Perform additional features selection\n",
    "feature_selection = SelectKBest(score_func=chi2, k=10)\n",
    "feature_selection.fit(X_train, y_train)\n",
    "mask = feature_selection.get_support()\n",
    "ranks = dict(zip(np.array(feature_list)[1:][mask], feature_selection.scores_))\n",
    "pprint.pprint(sorted(ranks.items(), key=lambda x: x[1], reverse=True))\n",
    "X_train = feature_selection.transform(X_train)\n",
    "X_test = feature_selection.transform(X_test)\n",
    "\n",
    "# Up sample features to account for class imbalance\n",
    "upsampler = ADASYN(ratio='minority', random_state=42)\n",
    "X_train, y_train = upsampler.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Task 4: Try a varity of classifiers\n",
    "# Please name your classifier clf for easy export below.\n",
    "# Note that if you want to do PCA or other multi-stage operations,\n",
    "# you'll need to use Pipelines. For more info:\n",
    "# http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "# Create first classifier\n",
    "clf = SVC(C=1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test first classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['non-poi', 'poi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Task 5: Tune your classifier to achieve better than .3 precision and recall\n",
    "# using our testing script. Check the tester.py script in the final project\n",
    "# folder for details on the evaluation method, especially the test_classifier\n",
    "# function. Because of the small size of the dataset, the script uses\n",
    "# stratified shuffle split cross validation. For more info:\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "test_classifier(clf, data_dict, feature_list, folds = 1000)\n",
    "\n",
    "# Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "# check your results. You do not need to change anything below, but make sure\n",
    "# that the version of poi_id.py that you submit can be run on its own and\n",
    "# generates the necessary .pkl files for validating your results.\n",
    "\n",
    "# dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass\n",
    "    #test_multiple(classifier_types, features_train, features_test, labels_train,\n",
    "    #labels_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
