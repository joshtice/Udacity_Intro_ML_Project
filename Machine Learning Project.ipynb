{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# General imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "# Udacity module imports\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data\n",
    "from tester import test_classifier\n",
    "\n",
    "# Scikit-Learn imports\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Task 1: Select what features you'll use.\n",
    "# features_list is a list of strings, each of which is a feature name.\n",
    "# The first feature must be \"poi\".\n",
    "\n",
    "feature_list = [\n",
    "    'poi',  \n",
    "    'bonus',\n",
    "    'deferral_payments',\n",
    "    'deferred_income',\n",
    "    'director_fees',\n",
    "    #'email_address',\n",
    "    'exercised_stock_options',\n",
    "    'expenses',\n",
    "    'from_messages',\n",
    "    'from_poi_to_this_person',\n",
    "    'from_this_person_to_poi',\n",
    "    'loan_advances',\n",
    "    'long_term_incentive',\n",
    "    'other',\n",
    "    'restricted_stock',\n",
    "    'restricted_stock_deferred',\n",
    "    'salary',\n",
    "    'shared_receipt_with_poi',\n",
    "    'to_messages',\n",
    "    'total_payments',\n",
    "    'total_stock_value'\n",
    "]  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 97343619,\n",
       " 'deferral_payments': 32083396,\n",
       " 'deferred_income': -27992891,\n",
       " 'director_fees': 1398517,\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 311764000,\n",
       " 'expenses': 5235198,\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 83925000,\n",
       " 'long_term_incentive': 48521928,\n",
       " 'other': 42667589,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 130322299,\n",
       " 'restricted_stock_deferred': -7576788,\n",
       " 'salary': 26704229,\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 309886585,\n",
       " 'total_stock_value': 434509511}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2: Remove outliers\n",
    "data_dict.pop('TOTAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Task 3: Create new feature(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import data into dataframe for EDA\n",
    "df = pd.DataFrame.from_records(list(data_dict.values()))\n",
    "employees = pd.Series(list(data_dict.keys()))\n",
    "df.set_index(employees, inplace=True)\n",
    "df.replace('NaN', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ng = sns.PairGrid(data=df, hue='poi')\\ng = g.map_diag(plt.hist)\\ng = g.map_offdiag(plt.scatter)\\nplt.show()\\n\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA\n",
    "\n",
    "#print('Shape: {}'.format(df.shape))\n",
    "#print(df.describe())\n",
    "#sns.boxplot(x='poi', y='bonus', data=df)\n",
    "'''\n",
    "g = sns.PairGrid(data=df, hue='poi')\n",
    "g = g.map_diag(plt.hist)\n",
    "g = g.map_offdiag(plt.scatter)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract features and labels from dataset for local testing\n",
    "dataset = featureFormat(data_dict, feature_list, sort_keys=True)\n",
    "labels, features = targetFeatureSplit(dataset)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    non-poi       0.91      0.82      0.86        39\n",
      "        poi       0.22      0.40      0.29         5\n",
      "\n",
      "avg / total       0.84      0.77      0.80        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "feature_selection = SelectKBest(score_func=chi2, k=5)\n",
    "classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['non-poi', 'poi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "feature_selection = SelectKBest(score_func=chi2, k=5)\n",
    "classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('feature_selection', feature_selection),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['non-poi', 'poi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('feature_selection', SelectKBest(k=5, score_func=<function chi2 at 0x115cf26e0>)), ('classifier', AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=...ndom_state=None, splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=100, random_state=42))])\n",
      "\tAccuracy: 0.81160\tPrecision: 0.30163\tRecall: 0.31400\tF1: 0.30769\tF2: 0.31145\n",
      "\tTotal predictions: 15000\tTrue positives:  628\tFalse positives: 1454\tFalse negatives: 1372\tTrue negatives: 11546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Try a varity of classifiers\n",
    "# Please name your classifier clf for easy export below.\n",
    "# Note that if you want to do PCA or other multi-stage operations,\n",
    "# you'll need to use Pipelines. For more info:\n",
    "# http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "\n",
    "\n",
    "# Task 5: Tune your classifier to achieve better than .3 precision and recall\n",
    "# using our testing script. Check the tester.py script in the final project\n",
    "# folder for details on the evaluation method, especially the test_classifier\n",
    "# function. Because of the small size of the dataset, the script uses\n",
    "# stratified shuffle split cross validation. For more info:\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "#test_classifier(clf, data_dict, feature_list, folds = 1000)\n",
    "\n",
    "# Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
    "# check your results. You do not need to change anything below, but make sure\n",
    "# that the version of poi_id.py that you submit can be run on its own and\n",
    "# generates the necessary .pkl files for validating your results.\n",
    "\n",
    "# dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass\n",
    "    #test_multiple(classifier_types, features_train, features_test, labels_train,\n",
    "    #labels_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
